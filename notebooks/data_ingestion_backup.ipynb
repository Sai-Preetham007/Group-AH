{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medical Data Ingestion Notebook\n",
        "\n",
        "This notebook demonstrates how to load and preprocess medical data from various sources for the RAG system.\n",
        "\n",
        "## Overview\n",
        "- Load Kaggle Disease Dataset\n",
        "- Process symptoms and diseases\n",
        "- Create vector embeddings\n",
        "- Store in vector database\n",
        "- Test data retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('../')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Kaggle Disease Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the main dataset\n",
        "dataset_path = Path(\"../data/raw/Disease Dataset/dataset.csv\")\n",
        "descriptions_path = Path(\"../data/raw/Disease Dataset/symptom_Description.csv\")\n",
        "precautions_path = Path(\"../data/raw/Disease Dataset/symptom_precaution.csv\")\n",
        "\n",
        "print(\"Loading Kaggle Disease Dataset...\")\n",
        "\n",
        "# Load main dataset\n",
        "df = pd.read_csv(dataset_path)\n",
        "print(f\"Main dataset loaded: {len(df)} records\")\n",
        "\n",
        "# Load descriptions\n",
        "descriptions_df = pd.read_csv(descriptions_path)\n",
        "print(f\"Descriptions loaded: {len(descriptions_df)} diseases\")\n",
        "\n",
        "# Load precautions\n",
        "precautions_df = pd.read_csv(precautions_path)\n",
        "print(f\"Precautions loaded: {len(precautions_df)} diseases\")\n",
        "\n",
        "# Merge datasets\n",
        "df_merged = df.merge(descriptions_df, on='Disease', how='left')\n",
        "df_merged = df_merged.merge(precautions_df, on='Disease', how='left')\n",
        "\n",
        "print(f\"Final merged dataset: {len(df_merged)} records with {len(df_merged.columns)} columns\")\n",
        "df_merged.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Analysis and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze the dataset\n",
        "print(\"=== Dataset Analysis ===\")\n",
        "print(f\"Total records: {len(df_merged)}\")\n",
        "print(f\"Unique diseases: {df_merged['Disease'].nunique()}\")\n",
        "\n",
        "# Get all symptoms\n",
        "all_symptoms = set()\n",
        "for col in [f'Symptom_{i}' for i in range(1, 18)]:\n",
        "    symptoms = df_merged[col].dropna().unique()\n",
        "    all_symptoms.update(symptoms)\n",
        "\n",
        "print(f\"Unique symptoms: {len(all_symptoms)}\")\n",
        "\n",
        "# Disease distribution\n",
        "disease_counts = df_merged['Disease'].value_counts()\n",
        "print(f\"\\nTop 10 diseases by frequency:\")\n",
        "print(disease_counts.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Store in Vector Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ChromaDB\n",
        "client = chromadb.PersistentClient(path=\"../data/chroma_db\")\n",
        "collection = client.get_or_create_collection(\n",
        "    name=\"medical_knowledge\",\n",
        "    metadata={\"description\": \"Medical disease and symptom knowledge base\"}\n",
        ")\n",
        "\n",
        "print(\"ChromaDB collection created/loaded\")\n",
        "\n",
        "# Add documents to collection\n",
        "ids = [f\"disease_{i}\" for i in range(len(disease_texts))]\n",
        "metadatas = [{\"disease\": df_merged.iloc[i]['Disease']} for i in range(len(disease_texts))]\n",
        "\n",
        "collection.add(\n",
        "    documents=disease_texts,\n",
        "    embeddings=disease_embeddings,\n",
        "    ids=ids,\n",
        "    metadatas=metadatas\n",
        ")\n",
        "\n",
        "print(f\"Added {len(disease_texts)} documents to vector database\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Data Retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test query: Find diseases with fever and cough\n",
        "query = \"I have fever and cough, what disease could this be?\"\n",
        "query_embedding = model.encode(query)\n",
        "\n",
        "results = collection.query(\n",
        "    query_embeddings=[query_embedding.tolist()],\n",
        "    n_results=5\n",
        ")\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"\\nTop 5 matching diseases:\")\n",
        "for i, (doc, metadata, distance) in enumerate(zip(results['documents'][0], results['metadatas'][0], results['distances'][0])):\n",
        "    print(f\"{i+1}. {metadata['disease']} (similarity: {1-distance:.3f})\")\n",
        "    print(f\"   {doc[:100]}...\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize disease distribution\n",
        "plt.figure(figsize=(12, 8))\n",
        "disease_counts.head(15).plot(kind='bar')\n",
        "plt.title('Top 15 Diseases by Frequency')\n",
        "plt.xlabel('Disease')\n",
        "plt.ylabel('Number of Records')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Vector Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize sentence transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Sentence transformer model loaded\")\n",
        "\n",
        "# Create embeddings for diseases and symptoms\n",
        "disease_embeddings = []\n",
        "disease_texts = []\n",
        "\n",
        "for _, row in df_merged.iterrows():\n",
        "    # Create text representation of disease\n",
        "    symptoms = []\n",
        "    for col in [f'Symptom_{i}' for i in range(1, 18)]:\n",
        "        if pd.notna(row[col]) and row[col].strip():\n",
        "            symptoms.append(row[col])\n",
        "    \n",
        "    disease_text = f\"Disease: {row['Disease']}. Symptoms: {', '.join(symptoms)}\"\n",
        "    if pd.notna(row.get('Description', '')):\n",
        "        disease_text += f\" Description: {row['Description']}\"\n",
        "    \n",
        "    disease_texts.append(disease_text)\n",
        "    disease_embeddings.append(model.encode(disease_text))\n",
        "\n",
        "print(f\"Created {len(disease_embeddings)} embeddings\")\n",
        "print(f\"Embedding dimension: {len(disease_embeddings[0])}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
